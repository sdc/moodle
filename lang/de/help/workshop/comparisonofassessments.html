<p align="center"><b>Vergleich von Bewertungen</b></p>

<p>Im Workshop wird üblicherweise die Arbeit gleichermassen vom Trainer und den TN 
bewertet. Wenn Musterlösungen verwandt werden, werden diese zuerst vom Trainer bewertet
 und danach einzelne Musterlösungen den Tn vorgelegt. Die Arbeiten der Tn werden
 sorgfältig vom Trainer kommentiert und bewertet und möglicherweise auch von
 einer kleinen Zahl anderer Tn. Der Trainer kann die Gewichtung der Bewertung einer 
 Arbeit durch andere Tn festlegen. Der Rest der Benotung besteht aus der Bewertung durch den
 Trainer. Die Gewichtung kann am Ende des Workshops festgelegt werden. Die Bewertungen,
 die die Tn durchführen können ebenfalls bewertet werden. Dabei richtet sich die Bewertung nach der
 Übereinstimmung mit der Bewertung des Trainers. Wenn der Trainer keine Note vergibt wird die durchschnittliche Bewertung 
 der Teilnehmer/inen zu Grunde gelegt.</p>

<p>Der Grad der Übereinstimmung zwischen der Bewertung durch die Tn und dem Trainer
basiert auf den Unterschieden zwischen den vergebenen Punkten bei den einzelnen
Bewertungskriterien. Diese müssen noch in eine nachvollziehbare Benotung übertragen werden.
Dazu erlaubt die Option "Vergleich der Bewertungen" dem Trainer eine genaue Kontrolle
wie die Vergleiche in Benotungen umgesetzt werden. </p>

<p>Damit Sie eine ungefähre Vorstellung der Wirkung dieser Option erhalten, sei
 es mit einem (wirklich einfachen) Beispiel demonstriert. 
 In unserem Beispiel erfolgt die Bewertung anhand von 1ß Ja/Nein Fragen.
 (z.B.: Die das Chart richtig formatiert? Oder: Ist der errechnete Gewinn 100,66 $?) 
Wenn die Einstellung "Sehr lax"" gewählt wurde, ergibt die völlständige 
Übereinstimmung zwischen den Bewertungen der Tn und des Trainers einen 
Ergebniswert von 100 %, ist nur eine Frage abweichend bewertet lautet das Ergebnis 90 %,
für jede weitere abweichend bewertete Frage sinkt der Wert um jeweils 10 %.
Diese Bewertung erscheint sehr logisch, aber warum wird sie als sehr lax bezeichent?
Stellen sie sich vor ein Tn vergibt die Bewertung nach dem Zufallsprinzip. Dann 
wird er wahrscheinlich 50% richtige Bewertungen vornehmen und erhält eine Bewertung 
von 50 % als Basis für die Note. 
Wenn die Einstellung auf lax geändert wird, wird der Zufallsfaktor mit 20 % gesetzt.
Mit der Fair Option auf 0 in den meisten Fällen. 
In diesem Level wird eine 50 % Bewertung vergeben, wenn zwei Bewertungen von zehn 
nicht übereinstimmen. Bei drei nicht übereinstimmenden Bewertungen wird eine 25 % 
Bewertung vergeben. Die Einstellung strickt führt bei zwei Nicht-Übereinstimmung 
zu einer Bewertung von 40%, sehr strickt zu einer Bewertung von 35% bei einer Nichtübereinstimmung.</p>

<p>Dieses Beispeil ist sicher ein wenig künstlich, da zumeist Bewertungsskalen
mit einer stärkeren Abstufung verwandt werden als nur Ja/Nein. Die berechnung des Ergebnisses des 
Vergleichs erfolgt jedoch in gleicher Weise. Die verschiedenen Level (sehr lax,
lax,  fair,...) dienen  nun dazu die Bewertung fein abzustimmen. Wenn Sie den Eindruck 
haben, die Bewertung ist zu niedrig, ändern Sie einfach den Level in Richtung 
sehr lax. Wenn Sie den Eindruck haben, die Bewertung ist insgesamt zu postiv, ändern Sie
den Level in Richtung sehr strickt. Es ist eine Frage des Ausprobierrens. Ein guter 
Startpunkt ist die mittlere Einstellung fair.</p>

<p>Während des Ablaufs des Workshops bekommen sie einen eindruck davon, ob die 
Bewertungen zu hoch oder zu niedrig sind. Die Benotungen sind in der Administrationsseite 
des Workshops ersichtlich. Sie können dann die Einstellungen anpassen und die 
Benotungen neu errechnen lassen. Die Neuberechnung erfolgt durch Klick auf den Link
Neubenotung der Arbeiten der Tn auf der Administrationsseite. Dies kann jederzeit im Verlauf des 
Workshops vorgenommen werden.  </p>

